{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBwGwcMs6Ekp"
      },
      "outputs": [],
      "source": [
        "# only necessary for google colab! to load models into session\n",
        "!git clone https://github.com/jyjblrd/S4_Slicer\n",
        "!mv S4_Slicer/* ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rYHWREkxIk1I"
      },
      "outputs": [],
      "source": [
        "!pip install tetgen\n",
        "!pip install pyvista\n",
        "!pip install scipy\n",
        "!pip install open3d\n",
        "!pip install pygcode\n",
        "!apt-get install -qq xvfb libgl1-mesa-glx\n",
        "!pip install pyvista -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpsFNDwvIhto"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pyvista as pv\n",
        "import tetgen\n",
        "from scipy.optimize import minimize, least_squares\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "import open3d as o3d\n",
        "import time\n",
        "import pickle\n",
        "import base64\n",
        "pv.set_jupyter_backend('static') # Google colab only allows static rendering. Download and run notepad locally to view in 3D!\n",
        "pv.global_theme.notebook = True\n",
        "pv.start_xvfb()\n",
        "\n",
        "def encode_object(obj):\n",
        "    return base64.b64encode(pickle.dumps(obj)).decode('utf-8')\n",
        "\n",
        "def decode_object(encoded_str):\n",
        "    return pickle.loads(base64.b64decode(encoded_str))\n",
        "\n",
        "up_vector = np.array([0, 0, 1])\n",
        "\n",
        "# Load mesh\n",
        "model_name = \"pi 3mm\"\n",
        "mesh = o3d.io.read_triangle_mesh(f'input_models/{model_name}.stl')\n",
        "\n",
        "# convert to tetrahedral mesh\n",
        "input_tet = tetgen.TetGen(np.asarray(mesh.vertices), np.asarray(mesh.triangles))\n",
        "# input_tet.make_manifold() # comment out if not needed\n",
        "input_tet.tetrahedralize()\n",
        "input_tet = input_tet.grid\n",
        "\n",
        "# rotate\n",
        "# input_tet = input_tet.rotate_x(-90) # b axis mount\n",
        "\n",
        "# scale\n",
        "# input_tet = input_tet.scale(1.5)\n",
        "\n",
        "# make origin center bottom of bounding box\n",
        "# PART_OFFSET = np.array([0., 10., 0.]) # z mount\n",
        "# PART_OFFSET = np.array([-13., -10., 0.]) # bunny\n",
        "# PART_OFFSET = np.array([60., 0., 0.]) # benchy\n",
        "# PART_OFFSET = np.array([0., 10., 0.]) # benchy upsidedown tilted\n",
        "# PART_OFFSET = np.array([0., 10., 0.]) # squirtle\n",
        "# PART_OFFSET = np.array([-44., 0., 0.]) # b axis mount\n",
        "# PART_OFFSET = np.array([50., 20., 0.]) # mew\n",
        "PART_OFFSET = np.array([0., 0., 0.])\n",
        "x_min, x_max, y_min, y_max, z_min, z_max = input_tet.bounds\n",
        "input_tet.points -= np.array([(x_min + x_max) / 2, (y_min + y_max) / 2, z_min]) + PART_OFFSET\n",
        "\n",
        "\n",
        "# find neighbours\n",
        "cell_neighbour_dict = {neighbour_type: {face: [] for face in range(input_tet.number_of_cells)} for neighbour_type in [\"point\", \"edge\", \"face\"]}\n",
        "for neighbour_type in [\"point\", \"edge\", \"face\"]:\n",
        "    cell_neighbours = []\n",
        "    for cell_index in range(input_tet.number_of_cells):\n",
        "        neighbours = input_tet.cell_neighbors(cell_index, f\"{neighbour_type}s\")\n",
        "        for neighbour in neighbours:\n",
        "            if neighbour > cell_index:\n",
        "                cell_neighbours.append((cell_index, neighbour))\n",
        "    for face_1, face_2 in np.array(cell_neighbours):\n",
        "        cell_neighbour_dict[neighbour_type][face_1].append(face_2)\n",
        "        cell_neighbour_dict[neighbour_type][face_2].append(face_1)\n",
        "\n",
        "    input_tet.field_data[f\"cell_{neighbour_type}_neighbours\"] = np.array(cell_neighbours)\n",
        "\n",
        "cell_neighbour_graph = nx.Graph()\n",
        "cell_centers = input_tet.cell_centers().points\n",
        "for edge in input_tet.field_data[\"cell_point_neighbours\"]: # use point neighbours for best accuracy\n",
        "    distance = np.linalg.norm(cell_centers[edge[0]] - cell_centers[edge[1]])\n",
        "    cell_neighbour_graph.add_weighted_edges_from([(edge[0], edge[1], distance)])\n",
        "\n",
        "def update_tet_attributes(tet):\n",
        "    '''\n",
        "    Calculate face normals, face centers, cell centers, and overhang angles for each cell in the tetrahedral mesh.\n",
        "    '''\n",
        "\n",
        "    surface_mesh = tet.extract_surface()\n",
        "    cell_to_face = decode_object(tet.field_data[\"cell_to_face\"])\n",
        "\n",
        "    # put general data in field_data for easy access\n",
        "    cells = tet.cells.reshape(-1, 5)[:, 1:] # assume all cells have 4 vertices\n",
        "    tet.add_field_data(cells, \"cells\")\n",
        "    cell_vertices = tet.points\n",
        "    tet.add_field_data(cell_vertices, \"cell_vertices\")\n",
        "    faces = surface_mesh.faces.reshape(-1, 4)[:, 1:] # assume all faces have 3 vertices\n",
        "    tet.add_field_data(faces, \"faces\")\n",
        "    face_vertices = surface_mesh.points\n",
        "    tet.add_field_data(face_vertices, \"face_vertices\")\n",
        "\n",
        "    tet.cell_data['face_normal'] = np.full((tet.number_of_cells, 3), np.nan)\n",
        "    surface_mesh_face_normals = surface_mesh.face_normals\n",
        "    for cell_index, face_indices in cell_to_face.items():\n",
        "        face_normals = surface_mesh_face_normals[face_indices]\n",
        "        # get the normal facing the most down\n",
        "        most_down_normal_index = np.argmin(face_normals[:, 2])\n",
        "        tet.cell_data['face_normal'][cell_index] = face_normals[most_down_normal_index]\n",
        "    tet.cell_data['face_normal'] =  tet.cell_data['face_normal'] / np.linalg.norm(tet.cell_data['face_normal'], axis=1)[:, None]\n",
        "\n",
        "    tet.cell_data['face_center'] = np.empty((tet.number_of_cells, 3))\n",
        "    tet.cell_data['face_center'][:,:] = np.nan\n",
        "    surface_mesh_cell_centers = surface_mesh.cell_centers().points\n",
        "    for cell_index, face_indices in cell_to_face.items():\n",
        "        face_centers = surface_mesh_cell_centers[face_indices]\n",
        "        # get the normal facing the most down\n",
        "        most_down_center_index = np.argmin(face_centers[:, 2])\n",
        "        tet.cell_data['face_center'][cell_index] = face_centers[most_down_center_index]\n",
        "\n",
        "    tet.cell_data[\"cell_center\"] = tet.cell_centers().points\n",
        "\n",
        "    # calculate bottom cells\n",
        "    bottom_cell_threshold = np.nanmin(tet.cell_data['face_center'][:, 2])+0.3\n",
        "    bottom_cells_mask = tet.cell_data['face_center'][:, 2] < bottom_cell_threshold\n",
        "    tet.cell_data['is_bottom'] = bottom_cells_mask\n",
        "    bottom_cells = np.where(bottom_cells_mask)[0]\n",
        "\n",
        "    face_normals = tet.cell_data['face_normal'].copy()\n",
        "    face_normals[bottom_cells_mask] = np.nan # make bottom faces not angled\n",
        "    overhang_angle = np.arccos(np.dot(face_normals, up_vector))\n",
        "    tet.cell_data['overhang_angle'] = overhang_angle\n",
        "\n",
        "    overhang_direction = face_normals[:, :2].copy()\n",
        "    overhang_direction /= np.linalg.norm(overhang_direction, axis=1)[:, None]\n",
        "    tet.cell_data['overhang_direction'] = overhang_direction\n",
        "\n",
        "    # calculate if cell will print in air by seeing if any cell centers along path to base are higher\n",
        "    IN_AIR_THRESHOLD = 1\n",
        "    tet.cell_data['in_air'] = np.full(tet.number_of_cells, False)\n",
        "\n",
        "    _, paths_to_bottom = nx.multi_source_dijkstra(cell_neighbour_graph, set(bottom_cells))\n",
        "\n",
        "    # put it in cell data\n",
        "    tet.cell_data['path_to_bottom'] = np.full((tet.number_of_cells, np.max([len(x) for x in paths_to_bottom.values()])), -1)\n",
        "    for cell_index, path_to_bottom in paths_to_bottom.items():\n",
        "        tet.cell_data['path_to_bottom'][cell_index, :len(path_to_bottom)] = path_to_bottom\n",
        "\n",
        "    # calculate if cell is in air\n",
        "    for cell_index in range(tet.number_of_cells):\n",
        "        path_to_bottom = paths_to_bottom[cell_index]\n",
        "        if len(path_to_bottom) > 1:\n",
        "            cell_heights = tet.cell_data['cell_center'][path_to_bottom, 2]\n",
        "            if np.any(cell_heights > tet.cell_data['cell_center'][cell_index, 2] + IN_AIR_THRESHOLD):\n",
        "                tet.cell_data['in_air'][cell_index] = True\n",
        "\n",
        "    return tet\n",
        "\n",
        "def calculate_tet_attributes(tet):\n",
        "    '''\n",
        "    Calculate shared vertices between cells, cell to face & face to cell relations, and bottom cells of the tetrahedral mesh.\n",
        "    '''\n",
        "\n",
        "    surface_mesh = tet.extract_surface()\n",
        "\n",
        "    # put general data in field_data for easy access\n",
        "    cells = tet.cells.reshape(-1, 5)[:, 1:] # assume all cells have 4 vertices\n",
        "    tet.add_field_data(cells, \"cells\")\n",
        "    cell_vertices = tet.points\n",
        "    tet.add_field_data(cell_vertices, \"cell_vertices\")\n",
        "    faces = surface_mesh.faces.reshape(-1, 4)[:, 1:] # assume all faces have 3 vertices\n",
        "    tet.add_field_data(faces, \"faces\")\n",
        "    face_vertices = surface_mesh.points\n",
        "    tet.add_field_data(face_vertices, \"face_vertices\")\n",
        "\n",
        "    # calculate shared vertices\n",
        "    shared_vertices = []\n",
        "    for cell_1, cell_2 in tet.field_data[\"cell_point_neighbours\"]:\n",
        "        shared_vertices_these_faces = np.intersect1d(cells[cell_1], cells[cell_2])\n",
        "        for vertex in shared_vertices_these_faces:\n",
        "            shared_vertices.append({\n",
        "                    \"cell_1_index\": cell_1,\n",
        "                    \"cell_2_index\": cell_2,\n",
        "                    \"cell_1_vertex_index\": np.where(cells[cell_1] == vertex)[0][0],\n",
        "                    \"cell_2_vertex_index\": np.where(cells[cell_2] == vertex)[0][0],\n",
        "                })\n",
        "\n",
        "    # calculate cell to face & face to cell relations\n",
        "    cell_to_face = {}\n",
        "    face_to_cell = {face_index: [] for face_index in range(len(faces))}\n",
        "    cell_to_face_vertices = {}\n",
        "    face_to_cell_vertices = {}\n",
        "    for cell_vertex_index, cell_vertex in enumerate(tet.field_data[\"cell_vertices\"].reshape(-1, 3)):\n",
        "        face_vertex_index = np.where((face_vertices == cell_vertex).all(axis=1))[0]\n",
        "        if len(face_vertex_index) == 1:\n",
        "            cell_to_face_vertices[cell_vertex_index] = face_vertex_index[0]\n",
        "            face_to_cell_vertices[face_vertex_index[0]] = cell_vertex_index\n",
        "\n",
        "    for cell_index, cell in enumerate(tet.field_data[\"cells\"]):\n",
        "        face_vertex_indices = [cell_to_face_vertices[cell_vertex_index] for cell_vertex_index in cell if cell_vertex_index in cell_to_face_vertices]\n",
        "        if len(face_vertex_indices) >= 3:\n",
        "            extracted = surface_mesh.extract_points(face_vertex_indices, adjacent_cells=False)\n",
        "            if extracted.number_of_cells >= 1:\n",
        "                cell_to_face[cell_index] = list(extracted.cell_data['vtkOriginalCellIds'])\n",
        "                for face_index in extracted.cell_data['vtkOriginalCellIds']:\n",
        "                    face_to_cell[face_index].append(cell_index)\n",
        "\n",
        "    tet.add_field_data(encode_object(cell_to_face), \"cell_to_face\")\n",
        "    tet.add_field_data(encode_object(face_to_cell), \"face_to_cell\")\n",
        "\n",
        "    # calculate has_face attribute\n",
        "    tet.cell_data['has_face'] = np.zeros(tet.number_of_cells)\n",
        "    for cell_index, face_indices in cell_to_face.items():\n",
        "        tet.cell_data['has_face'][cell_index] = 1\n",
        "\n",
        "    tet = update_tet_attributes(tet)\n",
        "\n",
        "    # calculate bottom cells\n",
        "    bottom_cells_mask = tet.cell_data['is_bottom']\n",
        "    bottom_cells = np.where(bottom_cells_mask)[0]\n",
        "\n",
        "    tet.cell_data['overhang_angle'][bottom_cells] = np.nan\n",
        "\n",
        "    return tet, bottom_cells_mask, bottom_cells\n",
        "\n",
        "\n",
        "bottom_cells_mask = None\n",
        "bottom_cells = None\n",
        "input_tet, bottom_cells_mask, bottom_cells = calculate_tet_attributes(input_tet)\n",
        "\n",
        "# find bottom cell groups that are connected\n",
        "bottom_cell_graph = nx.Graph()\n",
        "for cell_index in bottom_cells:\n",
        "    bottom_cell_graph.add_node(cell_index)\n",
        "cell_point_neighbour_dict = cell_neighbour_dict[\"point\"]\n",
        "for cell_index in bottom_cells:\n",
        "    for neighbour in cell_point_neighbour_dict[cell_index]:\n",
        "        if neighbour in bottom_cells:\n",
        "            bottom_cell_graph.add_edge(cell_index, neighbour)\n",
        "\n",
        "bottom_cell_groups = [list(x) for x in list(nx.connected_components(bottom_cell_graph))]\n",
        "\n",
        "undeformed_tet = input_tet.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-CJgbuVIhtr"
      },
      "outputs": [],
      "source": [
        "def planeFit(points):\n",
        "    \"\"\"\n",
        "    p, n = planeFit(points)\n",
        "\n",
        "    Given an array, points, of shape (d,...)\n",
        "    representing points in d-dimensional space,\n",
        "    fit an d-dimensional plane to the points.\n",
        "    Return a point, p, on the plane (the point-cloud centroid),\n",
        "    and the normal, n.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from numpy.linalg import svd\n",
        "    points = np.reshape(points, (np.shape(points)[0], -1))\n",
        "    assert points.shape[0] <= points.shape[1], \"There are only {} points in {} dimensions.\".format(points.shape[1], points.shape[0])\n",
        "    ctr = points.mean(axis=1)\n",
        "    x = points - ctr[:,np.newaxis]\n",
        "    M = np.dot(x, x.T)\n",
        "    return ctr, svd(M)[0][:,-1]\n",
        "\n",
        "def calculate_path_length_to_base_gradient(tet, MAX_OVERHANG, INITIAL_ROTATION_FIELD_SMOOTHING, SET_INITIAL_ROTATION_TO_ZERO):\n",
        "    '''\n",
        "    Calculate the path length to base gradient for each cell in the tetrahedral mesh with respect to the radial direction. This is used to determine the optimal rotation direction for each cell.\n",
        "\n",
        "    returns: path_length_to_base_gradient. A scalar for each cell in the tetrahedral mesh. This is the gradient in the radial direction of the path length to the closest bottom cell.\n",
        "    '''\n",
        "\n",
        "    # calculate initial rotation direction for each face\n",
        "    path_length_to_base_gradient = np.zeros((tet.number_of_cells)) # this is a scalar with respect to the radial direction. ie the vector pointing to the cell center\n",
        "\n",
        "    # find the path length for every overhang cell to a bottom cell\n",
        "    cell_distance_to_bottom = np.empty((tet.number_of_cells))\n",
        "    cell_distance_to_bottom[:] = np.nan\n",
        "    distances_to_bottom, paths_to_bottom = nx.multi_source_dijkstra(cell_neighbour_graph, set(bottom_cells))# set([x[0] for x in tet.field_data[\"bottom_cell_groups\"]]))\n",
        "    closest_bottom_cell_indices = np.zeros((tet.number_of_cells), dtype=int)\n",
        "    for cell_index in range(tet.number_of_cells):\n",
        "        face_normal = tet.cell_data[\"face_normal\"][cell_index]\n",
        "\n",
        "        cell_is_overhang = np.arccos(np.dot(face_normal, [0,0,1])) > np.deg2rad(90+MAX_OVERHANG)\n",
        "        if cell_is_overhang and cell_index not in bottom_cells:\n",
        "            closest_bottom_cell_indices[cell_index] = paths_to_bottom[cell_index][0]\n",
        "            cell_distance_to_bottom[cell_index] = distances_to_bottom[cell_index]\n",
        "\n",
        "    tet.cell_data[\"cell_distance_to_bottom\"] = cell_distance_to_bottom\n",
        "\n",
        "    # calculate the gradient of path length to base for each cell\n",
        "    for cell_index in range(tet.number_of_cells):\n",
        "        if not np.isnan(cell_distance_to_bottom[cell_index]):\n",
        "            local_cells = cell_neighbour_dict[\"edge\"][cell_index]\n",
        "            local_cells = np.hstack((local_cells, cell_index))\n",
        "            # add neighbours neighbours\n",
        "            # local_cells = neighbours.copy()\n",
        "            # for neighbour in neighbours:\n",
        "            #     local_cells.extend(cell_neighbour_dict[\"point\"][neighbour])\n",
        "            # local_cells = np.array(list(set(local_cells)))\n",
        "\n",
        "            local_cell_path_lengths = [cell_distance_to_bottom[local_cell] for local_cell in local_cells]\n",
        "            local_cell_path_lengths = np.array(local_cell_path_lengths)\n",
        "\n",
        "            # remove neighbours with path length of nan\n",
        "            local_cells = np.array(local_cells)[~np.isnan(local_cell_path_lengths)]\n",
        "            local_cell_path_lengths = local_cell_path_lengths[~np.isnan(local_cell_path_lengths)]\n",
        "\n",
        "            # if there are less than 3 neighbours with path length, roll to the closest bottom cell\n",
        "            if len(local_cell_path_lengths) < 3:\n",
        "                location_to_roll_to = tet.cell_data[\"cell_center\"][closest_bottom_cell_indices[cell_index], :2]\n",
        "\n",
        "                direction_to_bottom = location_to_roll_to - tet.cell_data[\"cell_center\"][cell_index, :2]\n",
        "                direction_to_bottom /= np.linalg.norm(direction_to_bottom)\n",
        "\n",
        "                cell_center = tet.cell_data[\"cell_center\"][cell_index, :2].copy()\n",
        "                cell_center /= np.linalg.norm(cell_center)\n",
        "\n",
        "                optimal_rotation_direction = np.dot(cell_center, direction_to_bottom) / np.abs(np.dot(cell_center, direction_to_bottom))\n",
        "                if np.isnan(optimal_rotation_direction):\n",
        "                    optimal_rotation_direction = 0\n",
        "\n",
        "                path_length_to_base_gradient[cell_index] = optimal_rotation_direction\n",
        "\n",
        "            # if there are 3 or more neighbours with path length, calculate the gradient in the radial direction\n",
        "            # and use that as the optimal rotation direction\n",
        "            else:\n",
        "                points = np.hstack((tet.cell_data[\"cell_center\"][local_cells, :2], local_cell_path_lengths[:, None]))\n",
        "                _, plane_normal = planeFit(points.T)\n",
        "\n",
        "                cell_center_direction_normalized = tet.cell_data[\"cell_center\"][cell_index, :2] / np.linalg.norm(tet.cell_data[\"cell_center\"][cell_index, :2])\n",
        "                gradient_in_radial_direction = np.dot(cell_center_direction_normalized, plane_normal[:2])\n",
        "\n",
        "                # if the gradient is nan, use the average of the neighbours\n",
        "                if np.isnan(gradient_in_radial_direction):\n",
        "                    gradient_in_radial_direction = np.mean(path_length_to_base_gradient[local_cells][~np.isnan(path_length_to_base_gradient[local_cells])])\n",
        "                    if np.isnan(gradient_in_radial_direction):\n",
        "                        gradient_in_radial_direction = 0\n",
        "\n",
        "                path_length_to_base_gradient[cell_index] = gradient_in_radial_direction\n",
        "\n",
        "    # smooth path_length_to_base_gradient with neighbours\n",
        "    # not needed because we do neighbour difference minimization in the optimization step?\n",
        "    if INITIAL_ROTATION_FIELD_SMOOTHING != 0:\n",
        "        for i in range(INITIAL_ROTATION_FIELD_SMOOTHING):\n",
        "            smoothed_path_length_to_base_gradient = np.zeros((tet.number_of_cells))\n",
        "            for cell_index in range(tet.number_of_cells):\n",
        "                if path_length_to_base_gradient[cell_index] != 0:\n",
        "                    neighbours = cell_neighbour_dict[\"point\"][cell_index]\n",
        "                    local_cells = neighbours.copy()\n",
        "                    for neighbour in neighbours:\n",
        "                        local_cells.extend(cell_neighbour_dict[\"point\"][neighbour])\n",
        "                    local_cells = np.array(list(set(local_cells)))\n",
        "                    local_cells = local_cells[path_length_to_base_gradient[local_cells]!=0]\n",
        "                    smoothed_path_length_to_base_gradient[cell_index] = np.mean(path_length_to_base_gradient[local_cells])\n",
        "\n",
        "        path_length_to_base_gradient = smoothed_path_length_to_base_gradient\n",
        "\n",
        "    # replace 0 with nan\n",
        "    if not SET_INITIAL_ROTATION_TO_ZERO:\n",
        "        path_length_to_base_gradient[path_length_to_base_gradient == 0] = np.nan\n",
        "    tet.cell_data[\"path_length_to_base_gradient\"] = path_length_to_base_gradient # very sexy\n",
        "\n",
        "    return path_length_to_base_gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwCL4ySfIhtr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_initial_rotation_field(tet, MAX_OVERHANG, ROTATION_MULTIPLIER, STEEP_OVERHANG_COMPENSATION, INITIAL_ROTATION_FIELD_SMOOTHING, SET_INITIAL_ROTATION_TO_ZERO, MAX_POS_ROTATION, MAX_NEG_ROTATION):\n",
        "    '''\n",
        "    Calculate the initial rotation field for each cell in the tetrahedral mesh to make overhangs less than MAX_OVERHANG.\n",
        "    The direction of rotation ensures the part is printable.\n",
        "    '''\n",
        "\n",
        "    # create initial rotation field rotating faces to be in safe printing angle\n",
        "    initial_rotation_field = np.full((tet.number_of_cells), np.nan)\n",
        "    initial_rotation_field = np.abs(np.deg2rad(90+MAX_OVERHANG) - tet.cell_data['overhang_angle'])\n",
        "\n",
        "    path_length_to_base_gradient = calculate_path_length_to_base_gradient(tet, MAX_OVERHANG, INITIAL_ROTATION_FIELD_SMOOTHING, SET_INITIAL_ROTATION_TO_ZERO)\n",
        "\n",
        "    # if path_length_to_base_gradient is different to the cell's overhang direction, it needs to be rotated an additional amount (its overhang angle) to make it go the right way\n",
        "    # Put behind a flag because it is normally not needed, and buggy/finnicky\n",
        "    # Can try enable it for models with very steep overhangs (>90 degrees) (not common)\n",
        "    if STEEP_OVERHANG_COMPENSATION:\n",
        "        initial_rotation_field[tet.cell_data[\"in_air\"]] += 2 * (np.deg2rad(180) - tet.cell_data['overhang_angle'][tet.cell_data[\"in_air\"]])\n",
        "\n",
        "    # # Apply the path_length_to_base_gradient (optimal overhang direction) to the initial rotation field\n",
        "    initial_rotation_field *= path_length_to_base_gradient\n",
        "\n",
        "    # apply rotation multiplier\n",
        "    initial_rotation_field = np.clip(initial_rotation_field*ROTATION_MULTIPLIER, -np.deg2rad(360), np.deg2rad(360))\n",
        "\n",
        "    # clip to max rotation\n",
        "    initial_rotation_field = np.clip(initial_rotation_field, MAX_NEG_ROTATION, MAX_POS_ROTATION)\n",
        "\n",
        "    tet.cell_data[\"initial_rotation_field\"] = initial_rotation_field\n",
        "\n",
        "    return initial_rotation_field\n",
        "\n",
        "from scipy.sparse import lil_matrix\n",
        "\n",
        "def calculate_rotation_matrices(tet, rotation_field):\n",
        "    '''\n",
        "    Calculate the rotation matrices for each cell in the tetrahedral mesh given the scalar\n",
        "    rotation field that gives a rotation for each cell. Cells are rotated around the axis\n",
        "    perpendicular to the radial direction and the z-axis.\n",
        "    '''\n",
        "\n",
        "    # create rotation matrix from theta around axis\n",
        "    tangential_vectors = np.cross( np.array([0, 0, 1]), tet.cell_data[\"cell_center\"][:, :2])\n",
        "    # normalize\n",
        "    tangential_vectors /= np.linalg.norm(tangential_vectors, axis=1)[:, None]\n",
        "    # replace nan with [1,0,0]\n",
        "    tangential_vectors[np.isnan(tangential_vectors).any(axis=1)] = [1, 0, 0]\n",
        "\n",
        "    rotation_matrices = R.from_rotvec(rotation_field[:, None] * tangential_vectors).as_matrix()\n",
        "\n",
        "    return rotation_matrices\n",
        "\n",
        "def calculate_unique_vertices_rotated(tet, rotation_field):\n",
        "    '''\n",
        "    Calculate the vertices of a tetrahedral mesh after rotating each cell by the rotation field.\n",
        "    Vertices are unique: they are not shared between cells.\n",
        "    '''\n",
        "\n",
        "    rotation_matrices = calculate_rotation_matrices(tet, rotation_field)\n",
        "\n",
        "    # rotate each face by the rotation field around its center\n",
        "    unique_vertices = np.zeros((tet.number_of_cells, 4, 3))\n",
        "    for cell_index, cell in enumerate(tet.field_data[\"cells\"]):\n",
        "        unique_vertices[cell_index] = tet.field_data[\"cell_vertices\"][cell]\n",
        "\n",
        "    cell_centers = tet.cell_data[\"cell_center\"]\n",
        "\n",
        "    unique_vertices_rotated = cell_centers.reshape(-1, 1, 3, 1) + rotation_matrices.reshape(-1, 1, 3, 3) @ (unique_vertices.reshape(-1, 4, 3, 1) - cell_centers.reshape(-1, 1, 3, 1))\n",
        "    # unique_vertices_rotated = rotation_matrices.reshape(-1, 1, 3, 3) @ unique_vertices.reshape(-1, 4, 3, 1)\n",
        "\n",
        "    return unique_vertices_rotated\n",
        "\n",
        "def apply_rotation_field_unique_vertices(tet, rotation_field):\n",
        "    '''\n",
        "    Apply the rotation field to the tetrahedral mesh and return a new tetrahedral mesh.\n",
        "    Vertices are unique: they are not shared between cells.\n",
        "    '''\n",
        "\n",
        "    unique_vertices_rotated = calculate_unique_vertices_rotated(tet, rotation_field)\n",
        "\n",
        "    unique_cells = np.zeros((tet.number_of_cells, 5), dtype=int)\n",
        "    unique_cells[:, 0] = 4\n",
        "    unique_cells[:, 1:] = np.arange(tet.number_of_cells*4).reshape(-1, 4)\n",
        "\n",
        "    new_tet = pv.UnstructuredGrid(unique_cells.flatten(), np.full(tet.number_of_cells, pv.CellType.TETRA), unique_vertices_rotated.reshape(-1, 3))\n",
        "\n",
        "    return new_tet\n",
        "\n",
        "def apply_rotation_field(tet, rotation_field):\n",
        "    '''\n",
        "    Apply the rotation field to the tetrahedral mesh and return a new tetrahedral mesh.\n",
        "    Vertices are shared between cells, so the surface is closed and smooth.\n",
        "    '''\n",
        "\n",
        "    new_vertices = np.zeros((tet.number_of_points, 3))\n",
        "    vertices_count = np.zeros((tet.number_of_points))\n",
        "    for cell in tet.field_data[\"cells\"]:\n",
        "        vertices_count[cell] += 1\n",
        "\n",
        "    unique_vertices_rotated = calculate_unique_vertices_rotated(tet, rotation_field)\n",
        "\n",
        "    for cell_index, vertices in enumerate(unique_vertices_rotated):\n",
        "        for i, vertex in enumerate(vertices):\n",
        "            new_vertices[tet.field_data[\"cells\"][cell_index, i]] += vertex.T[0] / vertices_count[tet.field_data[\"cells\"][cell_index][i]]\n",
        "\n",
        "    new_tet = pv.UnstructuredGrid(tet.cells, np.full(tet.number_of_cells, pv.CellType.TETRA), new_vertices)\n",
        "\n",
        "    return new_tet\n",
        "\n",
        "\n",
        "def optimize_rotations(tet, NEIGHBOUR_LOSS_WEIGHT, MAX_OVERHANG, ROTATION_MULTIPLIER, ITERATIONS, SAVE_GIF, STEEP_OVERHANG_COMPENSATION, INITIAL_ROTATION_FIELD_SMOOTHING, SET_INITIAL_ROTATION_TO_ZERO, MAX_POS_ROTATION, MAX_NEG_ROTATION):\n",
        "    '''\n",
        "    Optimize the rotation field for each cell in the tetrahedral mesh to make overhangs less\n",
        "    than MAX_OVERHANG while keeping the rotation field smooth.\n",
        "    '''\n",
        "\n",
        "    imgs = []\n",
        "    plotter = pv.Plotter(off_screen=True)\n",
        "    if SAVE_GIF:\n",
        "        plotter.open_gif(f'gifs/{model_name}_optimize_rotations.gif')\n",
        "\n",
        "    initial_rotation_field = calculate_initial_rotation_field(tet, MAX_OVERHANG, ROTATION_MULTIPLIER, STEEP_OVERHANG_COMPENSATION, INITIAL_ROTATION_FIELD_SMOOTHING, SET_INITIAL_ROTATION_TO_ZERO, MAX_POS_ROTATION, MAX_NEG_ROTATION)\n",
        "    num_cells_with_initial_rotation = np.sum(~np.isnan(initial_rotation_field))\n",
        "\n",
        "    def save_gif(rotation_field):\n",
        "        new_tet = apply_rotation_field_unique_vertices(tet, rotation_field)\n",
        "        new_tet.cell_data[\"rotation_field\"] = rotation_field\n",
        "        mesh_actor = plotter.add_mesh(new_tet,  clim=[-np.pi/4, np.pi/4], scalars=\"rotation_field\", lighting=False)\n",
        "        plotter.write_frame()\n",
        "        plotter.remove_actor(mesh_actor)\n",
        "\n",
        "    def objective_function(rotation_field):\n",
        "        '''\n",
        "        Objective function to minimize the neighbour losses and initial rotation losses.\n",
        "        '''\n",
        "        if SAVE_GIF:\n",
        "            save_gif(rotation_field)\n",
        "\n",
        "        # Compute neighbour losses using vectorized operations\n",
        "        cell_face_neighbours = tet.field_data[\"cell_face_neighbours\"]\n",
        "        neighbour_differences = rotation_field[cell_face_neighbours[:, 0]] - rotation_field[cell_face_neighbours[:, 1]]\n",
        "        neighbour_losses = NEIGHBOUR_LOSS_WEIGHT * neighbour_differences**2\n",
        "\n",
        "        # Compute the initial rotation losses\n",
        "        overhanging_mask = tet.cell_data['overhang_angle'] > np.deg2rad(90 + MAX_OVERHANG)\n",
        "        valid_cell_indices = np.where(~np.isnan(initial_rotation_field))[0]#np.where(overhanging_mask)[0]\n",
        "        initial_rotation_losses = (rotation_field[valid_cell_indices] - initial_rotation_field[valid_cell_indices])**2\n",
        "\n",
        "        # Return the concatenated losses\n",
        "        return np.concatenate((neighbour_losses, initial_rotation_losses))\n",
        "\n",
        "\n",
        "    def objective_jacobian(rotation_field):\n",
        "        start_time = time.time()\n",
        "        # Initialize the sparse matrix with LIL format for efficient row-wise operations\n",
        "        cell_face_neighbours = tet.field_data[\"cell_face_neighbours\"]\n",
        "        jac = lil_matrix((len(cell_face_neighbours) + num_cells_with_initial_rotation, tet.number_of_cells), dtype=np.float32)\n",
        "\n",
        "        # Vectorized computation for neighbour loss derivatives\n",
        "        cell_1 = cell_face_neighbours[:, 0]\n",
        "        cell_2 = cell_face_neighbours[:, 1]\n",
        "\n",
        "        # Compute the differences\n",
        "        differences = rotation_field[cell_1] - rotation_field[cell_2]\n",
        "\n",
        "        # Fill in the Jacobian for the first derivative of the neighbour loss function\n",
        "        jac[range(len(cell_face_neighbours)), cell_1] = 2 * NEIGHBOUR_LOSS_WEIGHT * differences\n",
        "        jac[range(len(cell_face_neighbours)), cell_2] = -2 * NEIGHBOUR_LOSS_WEIGHT * differences\n",
        "\n",
        "        # Vectorized computation for initial rotation loss derivatives\n",
        "        overhanging_mask = tet.cell_data['overhang_angle'] > np.deg2rad(90 + MAX_OVERHANG)\n",
        "        valid_cell_indices = np.where(~np.isnan(initial_rotation_field))[0]#np.where(overhanging_mask)[0]\n",
        "\n",
        "        # Fill in the Jacobian for the first derivative of the initial rotation loss function\n",
        "        jac[len(cell_face_neighbours) + np.arange(len(valid_cell_indices)), valid_cell_indices] = \\\n",
        "            2 * (rotation_field[valid_cell_indices] - initial_rotation_field[valid_cell_indices])\n",
        "\n",
        "        # print(\"Jacobian time:\", time.time() - start_time)\n",
        "        # Convert the LIL matrix to CSR format for efficient computations in further steps\n",
        "        return jac.tocsr()\n",
        "\n",
        "    def jac_sparsity():\n",
        "        cell_face_neighbours = tet.field_data[\"cell_face_neighbours\"]\n",
        "        sparsity = lil_matrix((len(cell_face_neighbours) + num_cells_with_initial_rotation, tet.number_of_cells), dtype=np.int8)\n",
        "\n",
        "        for i, (cell_1, cell_2) in enumerate(cell_face_neighbours):\n",
        "            sparsity[i, cell_1] = 1\n",
        "            sparsity[i, cell_2] = 1\n",
        "\n",
        "        valid_cell_indices = np.where(~np.isnan(initial_rotation_field))[0]#np.where(overhanging_mask)[0]\n",
        "        i = 0\n",
        "        for cell_index, initial_rotation in enumerate(initial_rotation_field):\n",
        "            if cell_index in valid_cell_indices:\n",
        "                sparsity[len(cell_face_neighbours) + i, cell_index] = 1\n",
        "                i += 1\n",
        "\n",
        "        return sparsity.tocsr()\n",
        "\n",
        "    smoothed_rotation_field = np.zeros((tet.number_of_cells))\n",
        "\n",
        "    # Optimization process to smooth the initial rotation field\n",
        "    result = least_squares(objective_function,\n",
        "                    smoothed_rotation_field,\n",
        "                    jac=objective_jacobian,\n",
        "                    max_nfev=ITERATIONS,\n",
        "                    jac_sparsity=jac_sparsity(),\n",
        "                    verbose=2,\n",
        "                    method='trf',\n",
        "                    ftol=1e-6,\n",
        "                    )\n",
        "\n",
        "    # render array of numpy images (imgs) into gif\n",
        "    if SAVE_GIF:\n",
        "        plotter.close()\n",
        "\n",
        "    return result.x\n",
        "\n",
        "NEIGHBOUR_LOSS_WEIGHT = 20 # the larger the weight, the more the rotation field will be smoothed\n",
        "MAX_OVERHANG = 30          # the maximum overhang angle in degrees\n",
        "ROTATION_MULTIPLIER = 2   # the larger the multiplier, the more the rotation field will be rotated\n",
        "SET_INITIAL_ROTATION_TO_ZERO = False # reduces influence of initial rotation field on non-overhanging tetrahedrons. good when initial rotation field is noisy\n",
        "INITIAL_ROTATION_FIELD_SMOOTHING = 30\n",
        "MAX_POS_ROTATION = np.deg2rad(3600) # normally set to 360 unless you get collisions\n",
        "MAX_NEG_ROTATION = np.deg2rad(-3600) # normally set to 360 unless you get collisions\n",
        "ITERATIONS = 100\n",
        "SAVE_GIF = True\n",
        "STEEP_OVERHANG_COMPENSATION = True\n",
        "\n",
        "rotation_field = optimize_rotations(\n",
        "    undeformed_tet,\n",
        "    NEIGHBOUR_LOSS_WEIGHT,\n",
        "    MAX_OVERHANG,\n",
        "    ROTATION_MULTIPLIER,\n",
        "    ITERATIONS,\n",
        "    SAVE_GIF,\n",
        "    STEEP_OVERHANG_COMPENSATION,\n",
        "    INITIAL_ROTATION_FIELD_SMOOTHING,\n",
        "    SET_INITIAL_ROTATION_TO_ZERO,\n",
        "    MAX_POS_ROTATION,\n",
        "    MAX_NEG_ROTATION\n",
        ")\n",
        "# rotation_field = calculate_initial_rotation_field(tet, MAX_OVERHANG, ROTATION_MULTIPLIER)\n",
        "undeformed_tet_with_rotated_tetrahedrons = apply_rotation_field_unique_vertices(undeformed_tet, rotation_field)\n",
        "undeformed_tet_with_rotated_tetrahedrons.cell_data[\"rotation_field\"] = rotation_field\n",
        "# new_tet.extract_cells(np.where(rotation_field != 0)[0]).plot()\n",
        "undeformed_tet_with_rotated_tetrahedrons.plot(scalars=\"rotation_field\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV5LNdPTIhts"
      },
      "source": [
        "default\n",
        "```\n",
        "NEIGHBOUR_LOSS_WEIGHT = 20 # the larger the weight, the more the rotation field will be smoothed\n",
        "MAX_OVERHANG = 30          # the maximum overhang angle in degrees\n",
        "ROTATION_MULTIPLIER = 2   # the larger the multiplier, the more the rotation field will be rotated\n",
        "SET_INITIAL_ROTATION_TO_ZERO = False # reduces influence of initial rotation field on non-overhanging tetrahedrons. good when initial rotation field is noisy\n",
        "```\n",
        "\n",
        "benchy upsidedown tilted\n",
        "scale: 1.5\n",
        "Iteration 1:\n",
        "```\n",
        "NEIGHBOUR_LOSS_WEIGHT = 100 # the larger the weight, the more the rotation field will be smoothed\n",
        "MAX_OVERHANG = 5          # the maximum overhang angle in degrees\n",
        "ROTATION_MULTIPLIER = 1   # the larger the multiplier, the more the rotation field will be rotated\n",
        "SET_INITIAL_ROTATION_TO_ZERO = True # reduces influence of initial rotation field on non-overhanging tetrahedrons. good when initial rotation field is noisy\n",
        "INITIAL_ROTATION_FIELD_SMOOTHING = 30\n",
        "```\n",
        "\n",
        "Iteration 2:\n",
        "```\n",
        "NEIGHBOUR_LOSS_WEIGHT = 50 # the larger the weight, the more the rotation field will be smoothed\n",
        "MAX_OVERHANG = 5          # the maximum overhang angle in degrees\n",
        "ROTATION_MULTIPLIER = 1   # the larger the multiplier, the more the rotation field will be rotated\n",
        "SET_INITIAL_ROTATION_TO_ZERO = True # reduces influence of initial rotation field on non-overhanging tetrahedrons. good when initial rotation field is noisy\n",
        "INITIAL_ROTATION_FIELD_SMOOTHING = 30\n",
        "```\n",
        "\n",
        "Iteration 3,4,5:\n",
        "```\n",
        "NEIGHBOUR_LOSS_WEIGHT = 50 # the larger the weight, the more the rotation field will be smoothed\n",
        "MAX_OVERHANG = 50          # the maximum overhang angle in degrees\n",
        "ROTATION_MULTIPLIER = 3   # the larger the multiplier, the more the rotation field will be rotated\n",
        "SET_INITIAL_ROTATION_TO_ZERO = True # reduces influence of initial rotation field on non-overhanging tetrahedrons. good when initial rotation field is noisy\n",
        "INITIAL_ROTATION_FIELD_SMOOTHING = 30\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aejPtKmnIhtt"
      },
      "outputs": [],
      "source": [
        "# view the initial rotation field we are trying to optimize towards\n",
        "# tet.extract_cells(tet.cell_data['overhang_angle'] > np.deg2rad(90 + MAX_OVERHANG)).plot(scalars=\"initial_rotation_field\")\n",
        "# tet.cell_data['overhang_angle'] > np.deg2rad(90 + MAX_OVERHANG)\n",
        "# undeformed_tet.plot(scalars=\"initial_rotation_field\")\n",
        "# undeformed_tet.plot(scalars=\"in_air\")\n",
        "undeformed_tet.plot(scalars=\"cell_distance_to_bottom\", cpos=[-0.5, -1, -1])\n",
        "# undeformed_tet.plot(scalars=\"overhang_angle\")\n",
        "# undeformed_tet.plot(scalars=\"path_length_to_base_gradient\")\n",
        "# undeformed_tet.plot(scalars=new_tet1.cell_data['rotation_field'])\n",
        "\n",
        "def show_path_to_base(tet, cell_index, plotter=pv.Plotter()):\n",
        "    path_to_bottom = tet.cell_data['path_to_bottom'][cell_index]\n",
        "    first_negative_index = np.where(path_to_bottom == -1)[0][0]\n",
        "    path_to_bottom = path_to_bottom[:first_negative_index]\n",
        "    print(path_to_bottom)\n",
        "\n",
        "    for i in range(len(path_to_bottom)-1):\n",
        "        path_to_base = pv.Line(tet.cell_data[\"cell_center\"][path_to_bottom[i]], tet.cell_data[\"cell_center\"][path_to_bottom[i+1]])\n",
        "        plotter.add_mesh(path_to_base, color=\"red\")\n",
        "\n",
        "    plotter.add_mesh(tet, opacity=0.2)\n",
        "    plotter.show()\n",
        "\n",
        "# show_path_to_base(tet, np.where(tet.cell_data['has_face'].astype(bool) & (tet.cell_data[\"overhang_angle\"] > 3))[0][7])\n",
        "\n",
        "def show_path_to_base_gradient_calculation(tet, cell_indices):\n",
        "    plotter = pv.Plotter()\n",
        "    scalar = np.full(tet.number_of_cells, 0.0)\n",
        "\n",
        "    for cell_index in cell_indices:\n",
        "        local_cells = cell_neighbour_dict[\"edge\"][cell_index]\n",
        "        local_cells = np.hstack((local_cells, cell_index))\n",
        "        local_cells_with_path_lengths = [x for x in local_cells if not np.isnan(tet.cell_data['cell_distance_to_bottom'][x])]\n",
        "        path_lengths = tet.cell_data['cell_distance_to_bottom'][local_cells_with_path_lengths]\n",
        "\n",
        "        cell_centers = tet.cell_data[\"cell_center\"][local_cells_with_path_lengths]\n",
        "        cell_centers_z_is_path_length = cell_centers.copy()\n",
        "        cell_centers_z_is_path_length[:, 2] = path_lengths - np.min(path_lengths) + np.min(cell_centers[:, 2])\n",
        "        points = pv.PolyData(cell_centers_z_is_path_length)\n",
        "        glyph = points.glyph(geom=pv.Sphere(theta_resolution=8, phi_resolution=8, radius=0.1))\n",
        "\n",
        "        if len(cell_centers_z_is_path_length) < 3:\n",
        "            continue\n",
        "\n",
        "        p, n = planeFit(cell_centers_z_is_path_length.T)\n",
        "        plane = pv.Plane(center=p, direction=n, i_size=4, j_size=4)\n",
        "        normal_arrow = pv.Arrow(start=p, direction=n, scale=1.5)\n",
        "\n",
        "        # reflect arrow across xy plane\n",
        "        reflected_n = -n - 2 * (np.dot(-n, up_vector)) * up_vector\n",
        "\n",
        "        # extract radial component\n",
        "        cell_center_direction_normalized = tet.cell_data[\"cell_center\"][cell_index, :2] / np.linalg.norm(tet.cell_data[\"cell_center\"][cell_index, :2])\n",
        "        gradient_in_radial_direction = np.dot(cell_center_direction_normalized, reflected_n[:2]) * cell_center_direction_normalized\n",
        "        nozzle_arrow = pv.Arrow(start=tet.cell_data[\"cell_center\"][cell_index], direction=np.hstack((gradient_in_radial_direction, reflected_n[2])), scale=1)\n",
        "\n",
        "\n",
        "        # plotter.add_mesh(glyph, color=\"blue\", opacity=0.5, )\n",
        "        # plotter.add_mesh(plane, color=\"green\", opacity=0.2)\n",
        "        # plotter.add_mesh(normal_arrow, color=\"orange\")\n",
        "        plotter.add_mesh(nozzle_arrow, color=\"red\")\n",
        "    scalar[local_cells_with_path_lengths] = 0.5\n",
        "    scalar[cell_index] = 1\n",
        "    plotter.add_mesh(tet, opacity=0.2, scalars=scalar, cmap=\"binary\")\n",
        "    plotter.show()\n",
        "\n",
        "# show_path_to_base_gradient_calculation(undeformed_tet, [np.where(tet.cell_data['has_face'].astype(bool) & (tet.cell_data[\"overhang_angle\"] > 3))[0][1]])\n",
        "# show_path_to_base_gradient_calculation(undeformed_tet, np.where(tet.cell_data['has_face'].astype(bool) & (tet.cell_data[\"overhang_angle\"] > np.deg2rad(90 + MAX_OVERHANG)))[0])\n",
        "\n",
        "def show_dijkstras(tet, cell_index):\n",
        "    plotter = pv.Plotter()#window_size=[3840, 2160])\n",
        "    lines = []\n",
        "    for neighbour in tet.field_data[\"cell_face_neighbours\"]:\n",
        "        lines += [tet.cell_data[\"cell_center\"][neighbour[0]], tet.cell_data[\"cell_center\"][neighbour[1]]]\n",
        "    mesh = pv.line_segments_from_points(lines)\n",
        "    plotter.add_mesh(mesh, color=\"grey\", opacity=0.4)\n",
        "\n",
        "    points = pv.PolyData(tet.cell_data[\"cell_center\"])\n",
        "    glyph = points.glyph(geom=pv.Sphere(theta_resolution=8, phi_resolution=8, radius=0.1))\n",
        "    plotter.add_mesh(glyph, color=\"red\", opacity=0.2)\n",
        "\n",
        "    if cell_index is None:\n",
        "        plotter.show()\n",
        "        return\n",
        "\n",
        "    plotter.camera_position = \"xz\"\n",
        "\n",
        "    # run dijkstra's algorithm and visualize\n",
        "    plotter.open_gif(f'gifs/{model_name}_dijkstra.gif')\n",
        "    distances, paths = nx.single_source_dijkstra(cell_neighbour_graph, cell_index)\n",
        "    dijkstra_actors = []\n",
        "    for i in np.arange(0, tet.cell_data['cell_distance_to_bottom'][cell_index], 0.2):\n",
        "        nodes_in_range = [node for node, distance in distances.items() if distance < i]\n",
        "        if len(nodes_in_range) == 0:\n",
        "            continue\n",
        "        if set(nodes_in_range) & set(bottom_cells):\n",
        "            break\n",
        "        points = pv.PolyData(tet.cell_data[\"cell_center\"][nodes_in_range])\n",
        "        glyph = points.glyph(geom=pv.Sphere(theta_resolution=8, phi_resolution=8, radius=0.2))\n",
        "        actor = plotter.add_mesh(glyph, color=\"blue\", opacity=0.4)\n",
        "        dijkstra_actors.append(actor)\n",
        "        plotter.write_frame()\n",
        "\n",
        "\n",
        "    path_to_bottom = tet.cell_data['path_to_bottom'][cell_index]\n",
        "    first_negative_index = np.where(path_to_bottom == -1)[0][0]\n",
        "    path_to_bottom = path_to_bottom[:first_negative_index]\n",
        "    print(path_to_bottom)\n",
        "\n",
        "    for i in range(len(path_to_bottom)-1):\n",
        "        path_to_base = pv.Line(tet.cell_data[\"cell_center\"][path_to_bottom[i]], tet.cell_data[\"cell_center\"][path_to_bottom[i+1]])\n",
        "        plotter.add_mesh(path_to_base, color=\"blue\", line_width=5)\n",
        "\n",
        "    for actor in dijkstra_actors:\n",
        "        plotter.remove_actor(actor)\n",
        "\n",
        "    plotter.write_frame()\n",
        "\n",
        "    plotter.show()\n",
        "    plotter.close()\n",
        "\n",
        "\n",
        "# show_dijkstras(undeformed_tet, np.where(tet.cell_data['has_face'].astype(bool) & (tet.cell_data[\"overhang_angle\"] > 3))[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS8QOmC9Ihtt"
      },
      "outputs": [],
      "source": [
        "N = np.eye(4) - 1/4 * np.ones((4, 4)) # the N matrix centers the vertices of a tetrahedron around the origin\n",
        "\n",
        "save_gif_i = 0\n",
        "\n",
        "def calculate_deformation(tet, rotation_field, ITERATIONS, SAVE_GIF):\n",
        "    '''\n",
        "    Try to find the optimal deformation of the tetrahedral mesh to make cells have the same rotation as\n",
        "    the given rotation field.\n",
        "\n",
        "    Our parameters are the vertices of the deformed mesh.\n",
        "    '''\n",
        "\n",
        "    new_vertices = tet.points.copy()\n",
        "\n",
        "    params = new_vertices.flatten()\n",
        "\n",
        "    rotation_matrices = calculate_rotation_matrices(tet, rotation_field)\n",
        "\n",
        "    # Extract old vertices for all cells\n",
        "    old_vertices = tet.field_data[\"cell_vertices\"][tet.field_data[\"cells\"]]\n",
        "    # Apply the transformation for all cells\n",
        "    old_vertices_transformed = np.einsum('ijk,ikl->ijl', rotation_matrices, (N @ old_vertices).transpose(0, 2, 1))\n",
        "\n",
        "    plotter = pv.Plotter(off_screen=True)\n",
        "\n",
        "    if SAVE_GIF:\n",
        "        plotter.open_gif(f'gifs/{model_name}_calculate_deformation.gif')\n",
        "\n",
        "    def save_gif(new_vertices):\n",
        "        global save_gif_i\n",
        "        save_gif_i += 1\n",
        "\n",
        "        if save_gif_i % 10 != 0:\n",
        "            return\n",
        "\n",
        "        new_tet = pv.UnstructuredGrid(tet.cells, np.full(tet.number_of_cells, pv.CellType.TETRA), new_vertices)\n",
        "        mesh_actor = plotter.add_mesh(new_tet)\n",
        "        plotter.write_frame()\n",
        "        plotter.remove_actor(mesh_actor)\n",
        "\n",
        "\n",
        "    def objective_function(params):\n",
        "        start_time = time.time()\n",
        "\n",
        "        new_vertices = params[:tet.number_of_points * 3].reshape(-1, 3)\n",
        "\n",
        "        if SAVE_GIF:\n",
        "            save_gif(new_vertices)\n",
        "\n",
        "        # Apply transformation for the new vertices\n",
        "        new_vertices_transformed = (N @ new_vertices[tet.field_data[\"cells\"]]).transpose(0, 2, 1)\n",
        "\n",
        "        # Calculate position compatibility loss using vectorized operations\n",
        "        position_losses = np.linalg.norm(new_vertices_transformed - old_vertices_transformed, axis=(1, 2))**2\n",
        "\n",
        "        # print(f\"Objective function took {time.time() - start_time} seconds\")\n",
        "        return position_losses\n",
        "\n",
        "    def objective_jacobian(params):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Initialize Jacobian matrix\n",
        "        J = lil_matrix((tet.number_of_cells, len(params)), dtype=np.float32)\n",
        "\n",
        "        # Extract parameters\n",
        "        new_vertices = params[:tet.number_of_points * 3].reshape(-1, 3)\n",
        "\n",
        "        # Extract old vertices for all cells\n",
        "        old_vertices = tet.field_data[\"cell_vertices\"][tet.field_data[\"cells\"]]\n",
        "\n",
        "        # Apply the transformation for old and new vertices\n",
        "        new_vertices_transformed = (N @ new_vertices[tet.field_data[\"cells\"]]).transpose(0, 2, 1)\n",
        "\n",
        "        # Compute the difference between transformed new and old vertices\n",
        "        diff = new_vertices_transformed - old_vertices_transformed  # shape: (num_cells, 3, num_vertices_per_cell)\n",
        "\n",
        "        # Reshape diff for easier broadcasting\n",
        "        diff = diff.transpose(0, 2, 1)  # shape: (num_cells, num_vertices_per_cell, 3)\n",
        "\n",
        "        # Now, for each cell, update the corresponding rows in the Jacobian\n",
        "        cell_indices = np.repeat(np.arange(tet.number_of_cells), len(tet.field_data[\"cells\"][0]))  # Cell indices repeated per vertex\n",
        "        vertex_indices = np.ravel(tet.field_data[\"cells\"])  # Flatten the cell-to-vertex mapping\n",
        "\n",
        "        # For each component x, y, z in the vertex, update the Jacobian\n",
        "        for dim in range(3):\n",
        "            J[cell_indices, vertex_indices * 3 + dim] = 2 * diff[:, :, dim].ravel()\n",
        "\n",
        "        # print(f\"Objective jacobian took {time.time() - start_time} seconds\")\n",
        "        return J.tocsr()\n",
        "\n",
        "    def jac_sparsity():\n",
        "        sparsity = lil_matrix((tet.number_of_cells, len(params)), dtype=np.int8)\n",
        "\n",
        "        cell_indices = np.repeat(np.arange(tet.number_of_cells), len(tet.field_data[\"cells\"][0]))\n",
        "        vertex_indices = np.ravel(tet.field_data[\"cells\"])\n",
        "\n",
        "        for dim in range(3):\n",
        "            sparsity[cell_indices, vertex_indices * 3 + dim] = 1\n",
        "\n",
        "        return sparsity.tocsr()\n",
        "\n",
        "    result = least_squares(objective_function,\n",
        "                    params,\n",
        "                    max_nfev=ITERATIONS,\n",
        "                    verbose=2,\n",
        "                    jac=objective_jacobian,\n",
        "                    jac_sparsity=jac_sparsity(),\n",
        "                    method='trf',\n",
        "                    x_scale='jac',\n",
        "                    )\n",
        "\n",
        "    plotter.close()\n",
        "\n",
        "    return result.x[:tet.number_of_points*3].reshape(-1, 3)\n",
        "\n",
        "ITERATIONS = 1000\n",
        "SAVE_GIF = True\n",
        "new_vertices = calculate_deformation(undeformed_tet, rotation_field, ITERATIONS, SAVE_GIF)\n",
        "deformed_tet = pv.UnstructuredGrid(undeformed_tet.cells, np.full(undeformed_tet.number_of_cells, pv.CellType.TETRA), new_vertices)\n",
        "deformed_tet.plot()\n",
        "\n",
        "for key in undeformed_tet.field_data.keys():\n",
        "    deformed_tet.field_data[key] = undeformed_tet.field_data[key]\n",
        "for key in undeformed_tet.cell_data.keys():\n",
        "    deformed_tet.cell_data[key] = undeformed_tet.cell_data[key]\n",
        "deformed_tet = update_tet_attributes(deformed_tet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epDO47CxIhtt"
      },
      "source": [
        "Run below to do another iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiSoiYVVIhtt"
      },
      "outputs": [],
      "source": [
        "undeformed_tet = deformed_tet.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_lRUzZEIhtt"
      },
      "source": [
        "Run below when finished deforming to save mesh as STL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1JPgprAIhtu"
      },
      "outputs": [],
      "source": [
        "# make origin center bottom of bounding box\n",
        "x_min, x_max, y_min, y_max, z_min, z_max = deformed_tet.bounds\n",
        "offsets_applied = np.array([(x_min + x_max) / 2, (y_min + y_max) / 2, z_min])\n",
        "deformed_tet.points -= offsets_applied\n",
        "\n",
        "deformed_tet.extract_surface().save(f'output_models/{model_name}_deformed_tet.stl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usEWXT8MIhtu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# save to pickle\n",
        "with open(f'pickle_files/deformed_{model_name}.pkl', 'wb') as f:\n",
        "    pickle.dump(deformed_tet, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yASyzpRpIhtu"
      },
      "source": [
        "# Now, go and slice the stl file in Cura!\n",
        "\n",
        "Settings:\n",
        "- Make the printer origin at the center of the buildplate\n",
        "- Dont use any pre/post scripts, z hop, etc. The config I use is provided in the github repo\n",
        "- Autoplace the model at the center by clicking \"Arrange All Models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suhUJh0fIhtu"
      },
      "outputs": [],
      "source": [
        "\n",
        "deformed_tet = pickle.load(open(f'pickle_files/deformed_{model_name}.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb8g9ObRIhtu"
      },
      "outputs": [],
      "source": [
        "def tetrahedron_volume(p1, p2, p3, p4):\n",
        "    '''\n",
        "    Calculate the volume of the tetrahedron formed by four points\n",
        "    '''\n",
        "\n",
        "    mat = np.vstack([p2 - p1, p3 - p1, p4 - p1])\n",
        "    return np.abs(np.linalg.det(mat)) / 6\n",
        "\n",
        "def calc_barycentric_coordinates(tet_a, tet_b, tet_c, tet_d, point):\n",
        "    '''\n",
        "    Calculate the barycentric coordinates of a point in a tetrahedron. This is used to interpolate\n",
        "    parameters from the vertices of the tetrahedron to a point within the tetrhedron.\n",
        "    '''\n",
        "\n",
        "    total_volume = tetrahedron_volume(tet_a, tet_b, tet_c, tet_d)\n",
        "\n",
        "    if total_volume == 0:\n",
        "        raise ValueError(\"The points do not form a valid tetrahedron (zero volume).\")\n",
        "\n",
        "    # Calculate the sub-volumes for each face\n",
        "    vol_a = tetrahedron_volume(point, tet_b, tet_c, tet_d)\n",
        "    vol_b = tetrahedron_volume(point, tet_a, tet_c, tet_d)\n",
        "    vol_c = tetrahedron_volume(point, tet_a, tet_b, tet_d)\n",
        "    vol_d = tetrahedron_volume(point, tet_a, tet_b, tet_c)\n",
        "\n",
        "    # Calculate barycentric coordinates as the ratio of sub-volumes to total volume\n",
        "    lambda_a = vol_a / total_volume\n",
        "    lambda_b = vol_b / total_volume\n",
        "    lambda_c = vol_c / total_volume\n",
        "    lambda_d = vol_d / total_volume\n",
        "\n",
        "    # The barycentric coordinates should sum to 1\n",
        "    return np.array([lambda_a, lambda_b, lambda_c, lambda_d])\n",
        "\n",
        "def project_point_onto_plane(plane_x_axis, plane_y_axis, point):\n",
        "    projected_x = np.sum(plane_x_axis * point, axis=1)\n",
        "    projected_y = np.sum(plane_y_axis * point, axis=1)\n",
        "\n",
        "    return np.array([projected_x, projected_y]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymN65RdPIhtu"
      },
      "outputs": [],
      "source": [
        "deformed_tet, _, _ = calculate_tet_attributes(deformed_tet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIvjkCmwIhtu"
      },
      "outputs": [],
      "source": [
        "from pygcode import Line\n",
        "import time\n",
        "\n",
        "SEG_SIZE = 0.6 # mm\n",
        "MAX_ROTATION = 90 # degrees\n",
        "MIN_ROTATION = -90 # degrees\n",
        "\n",
        "# find how each vertex in tet has been transformed\n",
        "vertex_transformations = deformed_tet.points - input_tet.points\n",
        "\n",
        "# calculate tangential vectors (axis of rotation) for each cell\n",
        "tangential_vectors = np.cross( np.array([0, 0, 1]), input_tet.cell_data[\"cell_center\"][:, :2])\n",
        "# normalize\n",
        "tangential_vectors /= np.linalg.norm(tangential_vectors, axis=1)[:, None]\n",
        "# replace nan with [1,0,0]\n",
        "tangential_vectors[np.isnan(tangential_vectors).any(axis=1)] = [1, 0, 0]\n",
        "\n",
        "# calculate rotation for each vertex and cell\n",
        "num_cells_per_vertex = np.zeros((input_tet.number_of_points))\n",
        "for cell_index, cell in enumerate(input_tet.field_data[\"cells\"]):\n",
        "    num_cells_per_vertex[cell] += 1\n",
        "vertex_rotations = np.zeros((deformed_tet.number_of_points))\n",
        "cell_rotations = np.zeros((deformed_tet.number_of_cells))\n",
        "for cell_index, cell in enumerate(deformed_tet.field_data[\"cells\"]):\n",
        "    new_vertices = deformed_tet.field_data[\"cell_vertices\"][cell]\n",
        "    new_cell_center = deformed_tet.cell_data[\"cell_center\"][cell_index]\n",
        "    old_vertices = input_tet.field_data[\"cell_vertices\"][cell]\n",
        "    old_cell_center = input_tet.cell_data[\"cell_center\"][cell_index]\n",
        "\n",
        "    # center points\n",
        "    new_vertices -= new_cell_center\n",
        "    old_vertices -= old_cell_center\n",
        "\n",
        "    # project on to radial plane\n",
        "    plane_x_vector = old_cell_center[:2] / np.linalg.norm(old_cell_center[:2])\n",
        "    plane_x_vector = np.array([plane_x_vector[0], plane_x_vector[1], 0])\n",
        "    plane_y_vector = np.array([0,0,1])\n",
        "\n",
        "    new_vertices_projected = project_point_onto_plane(plane_x_vector, plane_y_vector, new_vertices)\n",
        "    old_vertices_projected = project_point_onto_plane(plane_x_vector, plane_y_vector, old_vertices)\n",
        "\n",
        "    # find rotation between the two sets of points using the kabsch algorithm\n",
        "    covariance_matrix = np.dot(new_vertices_projected.T, old_vertices_projected)\n",
        "    U, _, Vt = np.linalg.svd(covariance_matrix)\n",
        "    rotation_matrix = np.dot(U, Vt)\n",
        "\n",
        "    # get rotation angle from matrix 2x2\n",
        "    rotation = -np.arccos(min(max(rotation_matrix[0, 0], -1), 1))\n",
        "    if rotation_matrix[1, 0] < 0:\n",
        "        rotation = -rotation\n",
        "\n",
        "    rotation = max(min(rotation, np.deg2rad(MAX_ROTATION)), np.deg2rad(MIN_ROTATION))\n",
        "\n",
        "    cell_rotations[cell_index] = rotation\n",
        "\n",
        "    for vertex_index in cell:\n",
        "        vertex_rotations[vertex_index] += rotation / num_cells_per_vertex[vertex_index]\n",
        "\n",
        "# calculate z squish scale for each cell (ratio of z length after rotation to z length before rotation)\n",
        "tet_rotation_matrices = calculate_rotation_matrices(input_tet, cell_rotations)\n",
        "z_squish_scales = np.full((deformed_tet.number_of_cells), np.nan)\n",
        "for cell_index, cell in enumerate(deformed_tet.field_data[\"cells\"]):\n",
        "    warped_vertices = deformed_tet.field_data[\"cell_vertices\"][cell]\n",
        "    unwarped_vertices = input_tet.field_data[\"cell_vertices\"][cell]\n",
        "\n",
        "    # rotate new vertices to align with old vertices\n",
        "    unwarped_vertices_rotated = (tet_rotation_matrices[cell_index].reshape(1, 3, 3) @ unwarped_vertices.reshape(4, 3, 1)).reshape(4, 3)\n",
        "\n",
        "    # calculate z squish scale\n",
        "    # z_squish_scales[cell_index] = (unwarped_vertices_rotated[:, 2].max() - unwarped_vertices_rotated[:, 2].min()) / (warped_vertices[:, 2].max() - warped_vertices[:, 2].min())\n",
        "    z_squish_scales[cell_index] = tetrahedron_volume(*unwarped_vertices) / tetrahedron_volume(*warped_vertices)\n",
        "    # z_squish_scales[cell_index] = min(z_squish_scales[cell_index], 5) # cap z squish scale\n",
        "\n",
        "\n",
        "# read gcode\n",
        "pos = np.array([0., 0., 20.])\n",
        "feed = 5000\n",
        "gcode_points = []\n",
        "with open(f'input_gcode/{model_name}_deformed_tet.gcode', 'r') as fh:\n",
        "    for line_text in fh.readlines():\n",
        "        line = Line(line_text)\n",
        "\n",
        "        if not line.block.gcodes:\n",
        "            continue\n",
        "\n",
        "        for gcode in sorted(line.block.gcodes):\n",
        "            if gcode.word == \"G01\" or gcode.word == \"G00\":\n",
        "                prev_pos = pos.copy()\n",
        "\n",
        "                if gcode.X is not None:\n",
        "                    pos[0] = gcode.X\n",
        "                if gcode.Y is not None:\n",
        "                    pos[1] = gcode.Y\n",
        "                if gcode.Z is not None:\n",
        "                    pos[2] = gcode.Z\n",
        "\n",
        "                inv_time_feed = None\n",
        "                # extract feed\n",
        "                for word in line.block.words:\n",
        "                    if word.letter == \"F\":\n",
        "                        feed = word.value\n",
        "\n",
        "                # extract extrusion\n",
        "                extrusion = None\n",
        "                for param in line.block.modal_params:\n",
        "                    if param.letter == \"E\":\n",
        "                        extrusion = param.value\n",
        "\n",
        "                # segment moves\n",
        "                # makes G1 (feed moves) less jittery\n",
        "                delta_pos = pos - prev_pos\n",
        "                distance = np.linalg.norm(delta_pos)\n",
        "                if distance > 0:\n",
        "                    num_segments = -(-distance // SEG_SIZE) # hacky round up\n",
        "                    seg_distance = distance/num_segments\n",
        "\n",
        "                    # calculate inverse time feed\n",
        "                    time_to_complete_move = (1/feed) * seg_distance # min/mm * mm = min\n",
        "                    if time_to_complete_move == 0:\n",
        "                        inv_time_feed = None\n",
        "                    else:\n",
        "                        inv_time_feed = 1/time_to_complete_move # 1/min\n",
        "\n",
        "                    for i in range(int(num_segments)):\n",
        "                        gcode_points.append({\n",
        "                            \"position\": (prev_pos + delta_pos * (i+1) / num_segments),\n",
        "                            \"command\": gcode.word,\n",
        "                            \"extrusion\": extrusion/num_segments if extrusion is not None else None,\n",
        "                            \"inv_time_feed\": inv_time_feed,\n",
        "                            \"move_length\": seg_distance,\n",
        "                            \"start_position\": prev_pos,\n",
        "                            \"end_position\": pos,\n",
        "                            \"unsegmented_move_length\": distance,\n",
        "                            \"after_retract\": False,\n",
        "                            \"feed\": feed\n",
        "                        })\n",
        "                else:\n",
        "                    # calculate inverse time feed\n",
        "                    time_to_complete_move = (1/feed) * distance # min/mm * mm = min\n",
        "                    if time_to_complete_move == 0:\n",
        "                        inv_time_feed = None\n",
        "                    else:\n",
        "                        inv_time_feed = 1/time_to_complete_move # 1/min\n",
        "\n",
        "                    gcode_points.append({\n",
        "                        \"position\": pos.copy(),\n",
        "                        \"command\": gcode.word,\n",
        "                        \"extrusion\": extrusion,\n",
        "                        \"inv_time_feed\": inv_time_feed,\n",
        "                        \"move_length\": distance,\n",
        "                        \"unsegmented_move_length\": distance,\n",
        "                        \"after_retract\": False,\n",
        "                        \"feed\": feed\n",
        "                    })\n",
        "\n",
        "                # # add G0 in same spot after retraction (so we can use it for zhop later)\n",
        "                # if gcode.word == \"G01\" and extrusion is not None and extrusion < 0:\n",
        "                #     gcode_points.append({\n",
        "                #         \"position\": pos.copy(),\n",
        "                #         \"command\": \"G00\",\n",
        "                #         \"extrusion\": None,\n",
        "                #         \"inv_time_feed\": None,\n",
        "                #         \"move_length\": 0,\n",
        "                #         \"after_retract\": True\n",
        "                #     })\n",
        "\n",
        "# calculate containging cell for each gcode point\n",
        "gcode_points_containing_cells = deformed_tet.find_containing_cell([point[\"position\"] for point in gcode_points])\n",
        "\n",
        "# for cells with no containing cell, find the closest cell\n",
        "gcode_points_closest_cells = deformed_tet.find_closest_cell([point[\"position\"] for point in gcode_points])\n",
        "# gcode_points_containing_cells[gcode_points_containing_cells == -1] = gcode_points_closest_cells[gcode_points_containing_cells == -1]\n",
        "\n",
        "# transform gcode points to original mesh's shape\n",
        "new_gcode_points = []\n",
        "prev_new_position = None\n",
        "travelling_over_air = False\n",
        "travelling = False\n",
        "prev_position = None\n",
        "prev_rotation = 0\n",
        "prev_travelling = False\n",
        "prev_command = \"G00\"\n",
        "ROTATION_AVERAGING_ALPHA = 0.2 # exponential moving average alpha for rotation\n",
        "RETRACTION_LENGTH = 1.0\n",
        "ROTATION_MAX_DELTA = np.deg2rad(1)\n",
        "MAX_EXTRUSION_MULTIPLIER = 10\n",
        "lost_vertices = []\n",
        "highest_printed_point = 0\n",
        "for cell_index, (gcode_point, containing_cell_index) in enumerate(zip(gcode_points, gcode_points_containing_cells)):\n",
        "    position = gcode_point[\"position\"]\n",
        "    command = gcode_point[\"command\"]\n",
        "    inv_time_feed = gcode_point[\"inv_time_feed\"]\n",
        "    extrusion = gcode_point[\"extrusion\"]\n",
        "\n",
        "    def barycentric_interpolate_to_get_new_position_and_rotation(position, containing_cell_index, command, cell_index):\n",
        "        if command == \"G00\" and containing_cell_index == -1: # Strict on travel moves being inside a tet\n",
        "            return None, None\n",
        "        if command == \"G01\" and containing_cell_index == -1: # Slightly more relaxed on printing moves\n",
        "            containing_cell_index = gcode_points_closest_cells[cell_index]\n",
        "\n",
        "        # get barycentric coordinates of pos in containing cell\n",
        "        vertiex_indices = deformed_tet.field_data[\"cells\"][containing_cell_index]\n",
        "        cell_vertices = deformed_tet.field_data[\"cell_vertices\"][vertiex_indices]\n",
        "        barycentric_coordinates = calc_barycentric_coordinates(cell_vertices[0], cell_vertices[1], cell_vertices[2], cell_vertices[3], position)\n",
        "\n",
        "        if np.sum(barycentric_coordinates) > 1.01:\n",
        "            return None, None\n",
        "\n",
        "        # calculate the new position of the point using the barycentric coordinates to weigh the vertex transformations\n",
        "        # multiply barycentric coordinates row-wise with vertex transformations\n",
        "        transformation = vertex_transformations[vertiex_indices] * barycentric_coordinates[:, None]\n",
        "\n",
        "        # sum columns\n",
        "        transformation = np.sum(transformation, axis=0)\n",
        "        # apply to pos\n",
        "        new_position = position - transformation\n",
        "\n",
        "        # do the same for rotation\n",
        "        rotation = np.sum(vertex_rotations[vertiex_indices] * barycentric_coordinates)\n",
        "\n",
        "        return new_position, rotation\n",
        "\n",
        "    dont_smooth_rotation = False\n",
        "    new_position, rotation = barycentric_interpolate_to_get_new_position_and_rotation(position, containing_cell_index, command, cell_index)\n",
        "    if new_position is None:\n",
        "        if command == \"G01\":\n",
        "            lost_vertices.append(position)\n",
        "            continue\n",
        "        elif command == \"G00\" and not travelling_over_air and prev_new_position is not None:\n",
        "            new_position = np.array([prev_new_position[0], prev_new_position[1], highest_printed_point]) # z hop over gap\n",
        "            rotation = max(min(prev_rotation, np.deg2rad(45)), np.deg2rad(-45)) # set rotation to a max of 45 because if rotation is very large, the extruder can \"hang below\" the nozzle and hit the part\n",
        "            dont_smooth_rotation = True # force rotation immediately\n",
        "            travelling_over_air = True\n",
        "        elif travelling_over_air:\n",
        "            continue\n",
        "        else:\n",
        "            continue\n",
        "    else:\n",
        "        if travelling_over_air:\n",
        "            new_position[2] = highest_printed_point # finish z hop over gap\n",
        "            rotation = max(min(rotation, np.deg2rad(45)), np.deg2rad(-45)) # set rotation to 0 because if rotation is very large, the extruder can \"hang below\" the nozzle and hit the part\n",
        "            dont_smooth_rotation = True # force rotation immediately\n",
        "        travelling_over_air = False\n",
        "\n",
        "    extrusion_multiplier = 3\n",
        "    if extrusion is not None and extrusion != RETRACTION_LENGTH and extrusion != -RETRACTION_LENGTH:\n",
        "\n",
        "        # scale extrusion by z_squish_scale\n",
        "        extrusion_multiplier = extrusion_multiplier * z_squish_scales[containing_cell_index]\n",
        "        extrusion = extrusion * min(extrusion_multiplier, MAX_EXTRUSION_MULTIPLIER)\n",
        "    elif extrusion == -RETRACTION_LENGTH:\n",
        "        travelling = True\n",
        "    elif extrusion == RETRACTION_LENGTH:\n",
        "        travelling = False\n",
        "    if prev_rotation is not None and not dont_smooth_rotation:\n",
        "        rotation = ROTATION_AVERAGING_ALPHA * rotation + (1 - ROTATION_AVERAGING_ALPHA) * prev_rotation\n",
        "\n",
        "    # if rotation delta between points is too high, add intermediate interpolation points to prevent nozzle from hitting part as rotating\n",
        "    if prev_rotation is not None and prev_new_position is not None and np.abs(rotation - prev_rotation) > ROTATION_MAX_DELTA:\n",
        "        delta_rotation = rotation - prev_rotation\n",
        "        num_interpolations = int(np.abs(delta_rotation) / ROTATION_MAX_DELTA) + 1\n",
        "        delta_pos = new_position - prev_new_position\n",
        "        for i in range(num_interpolations):\n",
        "            new_gcode_points.append({\n",
        "                \"position\": prev_new_position + (delta_pos * ((i+1) / num_interpolations)),\n",
        "                \"original_position\": position,\n",
        "                \"rotation\": prev_rotation + (delta_rotation * ((i+1) / num_interpolations)),\n",
        "                \"command\": prev_command,\n",
        "                \"extrusion\": extrusion/num_interpolations if extrusion is not None else None,\n",
        "                \"inv_time_feed\": inv_time_feed * num_interpolations if inv_time_feed is not None else None,\n",
        "                \"extrusion_multiplier\": extrusion_multiplier,\n",
        "                \"feed\": gcode_point[\"feed\"],\n",
        "                \"travelling\": prev_travelling\n",
        "            })\n",
        "    else:\n",
        "        new_gcode_points.append({\n",
        "            \"position\": new_position,\n",
        "            \"original_position\": position,\n",
        "            \"rotation\": rotation,\n",
        "            \"command\": command,\n",
        "            \"extrusion\": extrusion,\n",
        "            \"inv_time_feed\": inv_time_feed,\n",
        "            \"extrusion_multiplier\": extrusion_multiplier,\n",
        "            \"feed\": gcode_point[\"feed\"],\n",
        "            \"travelling\": travelling\n",
        "        })\n",
        "\n",
        "    prev_rotation = rotation\n",
        "    prev_new_position = new_position.copy()\n",
        "    prev_travelling = travelling\n",
        "    prev_command = command\n",
        "\n",
        "    if command == \"G01\" and extrusion is not None and extrusion > 0 and (highest_printed_point != 0 or new_position[2] < 1):\n",
        "        highest_printed_point = max(highest_printed_point, new_position[2])\n",
        "\n",
        "\n",
        "print(f\"Lost {len(lost_vertices)} vertices\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGQxjYmjIhtu"
      },
      "outputs": [],
      "source": [
        "\n",
        "prev_r = 0\n",
        "prev_theta = 0\n",
        "prev_z = 20\n",
        "PIVOT_X = -6.25\n",
        "BED_OFFSET = 17.2\n",
        "theta_accum = 0\n",
        "\n",
        "# save transformed gcode\n",
        "with open(f'output_gcode/{model_name}.gcode', 'w') as fh:\n",
        "    # write header\n",
        "    fh.write(\"G28 ; home \\n\")\n",
        "    fh.write(\"M104 S220 ; home \\n\")\n",
        "    fh.write(\"M105 ; home \\n\")\n",
        "    fh.write(\"M109 S220 ; home \\n\")\n",
        "    fh.write(\"M83 ; relative extrusion \\n\")\n",
        "    fh.write(\"G1 E20 ; prime extruder \\n\")\n",
        "    fh.write(\"G90 ; absolute positioning \\n\")\n",
        "\n",
        "\n",
        "    for i, point in enumerate(new_gcode_points):\n",
        "        position = point[\"position\"]\n",
        "        rotation = point[\"rotation\"]\n",
        "\n",
        "        if np.all(np.isnan(position)):\n",
        "            continue\n",
        "\n",
        "        if position[2] < 0:\n",
        "            continue\n",
        "\n",
        "        z_hop = 0\n",
        "        if point[\"travelling\"]:\n",
        "            z_hop = 1\n",
        "\n",
        "        #NEW\n",
        "        phi = rotation\n",
        "        l = position[0] - PIVOT_X\n",
        "\n",
        "        delta_x = (np.cos(phi) - 1) * l + np.sin(phi) * (BED_OFFSET + z_hop)\n",
        "        delta_z = -np.sin(phi) * l + (np.cos(phi) - 1) * (BED_OFFSET + z_hop) + z_hop\n",
        "\n",
        "        new_x = position[0] + delta_x\n",
        "        new_y = 100 + position[1]  # unchanged; assumes tilt doesn't affect Y (around Y-axis)\n",
        "        new_z = position[2] + delta_z\n",
        "\n",
        "        # convert to polar coordinates\n",
        "        r = np.linalg.norm(position[:2])\n",
        "        theta = np.arctan2(position[1], position[0])\n",
        "        z = position[2]\n",
        "\n",
        "        # compensate for nozzle offset\n",
        "        #r += -np.sin(rotation) * (NOZZLE_OFFSET + z_hop)\n",
        "        #z += (np.cos(rotation) - 1) * (NOZZLE_OFFSET + z_hop) + z_hop\n",
        "\n",
        "        delta_theta = theta - prev_theta\n",
        "        if delta_theta > np.pi:\n",
        "            delta_theta -= 2*np.pi\n",
        "        if delta_theta < -np.pi:\n",
        "            delta_theta += 2*np.pi\n",
        "\n",
        "        theta_accum += delta_theta\n",
        "\n",
        "        #string = f\"{point['command']} C{np.rad2deg(theta_accum):.5f} X{r:.5f} Z{z:.5f} B{np.rad2deg(rotation):.5f}\" # polar printer\n",
        "        #string = f\"{point['command']} X{position[0]:.5f} Y{position[1]:.5f} Z{position[2]} A{np.rad2deg(rotation):.5f}\" # cartesian printer (3 axis)\n",
        "\n",
        "        string = f\"{point['command']} X{new_x:.5f} Y{new_y:.5f} Z{new_z:.5f} A{np.rad2deg(phi):.5f}\"\n",
        "\n",
        "        if point[\"extrusion\"] is not None:\n",
        "            string += f\" E{point['extrusion']:.4f}\"\n",
        "\n",
        "        no_feed_value = False\n",
        "        if point[\"inv_time_feed\"] is not None:\n",
        "            string += f\" F{(point['inv_time_feed']):.4f}\"\n",
        "        else:\n",
        "            string += f\" F20000\"\n",
        "            fh.write(f\"G94\\n\")\n",
        "            no_feed_value = True\n",
        "\n",
        "        fh.write(string + \"\\n\")\n",
        "\n",
        "        if no_feed_value:\n",
        "            fh.write(f\"G93\\n\") # back to inv feed\n",
        "\n",
        "        # update previous values\n",
        "        #prev_r = r\n",
        "        #prev_theta = theta\n",
        "        prev_z = new_z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7GiEPfoIhtv"
      },
      "outputs": [],
      "source": [
        "# plot new_gcode_points using pyvista\n",
        "temp = np.array([point[\"position\"] for point in new_gcode_points])\n",
        "#temp = np.array(a)\n",
        "temp = pv.PolyData(temp)\n",
        "temp.cell_data[\"rotation\"] = np.array([np.rad2deg(point[\"rotation\"]) for point in new_gcode_points])\n",
        "temp.cell_data[\"travelling\"] = np.array([point[\"travelling\"] for point in new_gcode_points])\n",
        "temp.cell_data[\"delta_rotation\"] = np.clip(np.array([1] + [np.rad2deg(new_gcode_points[i+1][\"rotation\"] - new_gcode_points[i][\"rotation\"]) for i in range(len(new_gcode_points)-1)]), -10, 10)\n",
        "temp.cell_data[\"command\"] = np.array([point[\"command\"] for point in new_gcode_points])\n",
        "temp.cell_data[\"feed\"] = np.array([min(point[\"feed\"], 10000) for point in new_gcode_points])\n",
        "temp.cell_data[\"original_z\"] = np.array([point[\"original_position\"][2] for point in new_gcode_points])\n",
        "temp.cell_data[\"original_z_bands\"] = temp.cell_data[\"original_z\"] % 1\n",
        "temp.cell_data[\"extrusion_multiplier\"] = np.array([min(point[\"extrusion_multiplier\"], 15) if point[\"extrusion_multiplier\"] is not None else np.nan for point in new_gcode_points])\n",
        "\n",
        "temp.extract_cells(np.array([point[\"command\"] for point in new_gcode_points]) == \"G01\").plot(scalars=\"original_z_bands\", cpos=[-0.5, -1, 0.5], point_size=10)\n",
        "# .extract_cells(np.array([point[\"command\"] for point in new_gcode_points]) == \"G01\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgtHILG1Ihtv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plot the gcode\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "cmap = plt.get_cmap('viridis')\n",
        "rotation_normalized = temp.cell_data[\"rotation\"] / np.max(np.abs(temp.cell_data[\"rotation\"]),axis=0)\n",
        "colors = cmap(rotation_normalized)\n",
        "# for i in np.arange(len(temp.points)-1):\n",
        "#     ax.plot(\n",
        "#         [temp.points[i,0],temp.points[i+1,0]],\n",
        "#         [temp.points[i,1],temp.points[i+1,1]],\n",
        "#         [temp.points[i,2],temp.points[i+1,2]],\n",
        "#         c=colors[i],\n",
        "#         markersize=0.8, linewidth=0.9, marker='.', alpha=0.5)\n",
        "# plot G00 moves in different color\n",
        "g00_indices = np.where(temp.cell_data[\"command\"] == \"G00\")[0]\n",
        "g01_indices = np.where(temp.cell_data[\"command\"] == \"G01\")[0]\n",
        "ax.plot(temp.points[g00_indices,0], temp.points[g00_indices,1], temp.points[g00_indices,2], markersize=0.4, linewidth=0.3, marker=\".\", alpha=0.5, color=\"red\")\n",
        "ax.plot(temp.points[g01_indices,0], temp.points[g01_indices,1], temp.points[g01_indices,2], markersize=0.4, linewidth=0.3, marker=\".\", alpha=0.5, color=\"blue\")\n",
        "ax.set_box_aspect((np.ptp(temp.points[:,0]), np.ptp(temp.points[:,1]), np.ptp(temp.points[:,2])))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kWzGfmqsoFcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define input and output paths\n",
        "input_path = 'output_gcode/pi 3mm.gcode'\n",
        "output_path = 'output_gcode/pi 3mm.gcode'\n",
        "\n",
        "# Read the input file\n",
        "with open(input_path, 'r') as infile:\n",
        "    lines = infile.readlines()\n",
        "\n",
        "# Process each line: replace G00 with G0 and G01 with G1\n",
        "processed_lines = []\n",
        "for line in lines:\n",
        "    line = line.replace('G00', 'G0')\n",
        "    line = line.replace('G01', 'G1')\n",
        "    processed_lines.append(line)\n",
        "\n",
        "# Write to the output file\n",
        "with open(output_path, 'w') as outfile:\n",
        "    outfile.writelines(processed_lines)\n",
        "\n",
        "print(f\"Processed file saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "rIde_WUc7nhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies if needed (but numpy and matplotlib are pre-installed in Colab)\n",
        "# !pip install numpy matplotlib  # Uncomment if issues\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# User-configurable variables (edit these as needed)\n",
        "gcode_file = 'output_gcode/pi 3mm.gcode'  # Upload your G-code to Colab and set the path (e.g., '/content/your_model.gcode')\n",
        "bed_offset = 41.5  # mm\n",
        "pivot_x = 117.5  # mm\n",
        "bed_size_x = 235  # mm\n",
        "bed_size_y = 235  # mm\n",
        "simulate_bed = True  # Set to False to disable bed simulation\n",
        "\n",
        "# Function to parse G-code\n",
        "def parse_gcode(file_path):\n",
        "    moves = []\n",
        "    current_pos = {'X': 0, 'Y': 0, 'Z': 0, 'A': 0, 'E': 0}\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(';'):\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            command = parts[0]\n",
        "            if command not in ['G0', 'G1']:\n",
        "                continue\n",
        "            params = {}\n",
        "            for part in parts[1:]:\n",
        "                if part[0] in ['X', 'Y', 'Z', 'A', 'E', 'F']:\n",
        "                    params[part[0]] = float(part[1:])\n",
        "            for key in ['X', 'Y', 'Z', 'A', 'E']:\n",
        "                if key in params:\n",
        "                    current_pos[key] = params[key]\n",
        "            moves.append({\n",
        "                'command': command,\n",
        "                'X': current_pos['X'],\n",
        "                'Y': current_pos['Y'],\n",
        "                'Z': current_pos['Z'],\n",
        "                'A': current_pos['A'],\n",
        "                'E': current_pos.get('E', 0),\n",
        "            })\n",
        "    return moves\n",
        "\n",
        "# Function to simulate bed surface\n",
        "def simulate_bed_surface(x_grid, y_grid, phi_rad, pivot_x, bed_offset):\n",
        "    l_grid = x_grid - pivot_x\n",
        "    delta_z_bed = -np.sin(phi_rad) * l_grid + (np.cos(phi_rad) - 1) * bed_offset\n",
        "    return delta_z_bed\n",
        "\n",
        "# Function to visualize\n",
        "def visualize_gcode(moves, bed_offset, pivot_x, bed_size_x=235, bed_size_y=235, simulate_bed=True):\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    xs, ys, zs, As, commands, extrusions = [], [], [], [], [], []\n",
        "    for move in moves:\n",
        "        xs.append(move['X'])\n",
        "        ys.append(move['Y'])\n",
        "        zs.append(move['Z'])\n",
        "        As.append(move['A'])\n",
        "        commands.append(move['command'])\n",
        "        extrusions.append(move['E'])\n",
        "\n",
        "    xs = np.array(xs)\n",
        "    ys = np.array(ys)\n",
        "    zs = np.array(zs)\n",
        "    As = np.array(As)\n",
        "\n",
        "    prev_x, prev_y, prev_z = None, None, None\n",
        "    for i in range(len(moves)):\n",
        "        if prev_x is not None:\n",
        "            color = 'red' if commands[i] == 'G1' and extrusions[i] > 0 else 'blue'\n",
        "            ax.plot([prev_x, xs[i]], [prev_y, ys[i]], [prev_z, zs[i]], color=color, alpha=0.7)\n",
        "        prev_x, prev_y, prev_z = xs[i], ys[i], zs[i]\n",
        "\n",
        "    scatter = ax.scatter(xs, ys, zs, c=As, cmap='coolwarm', s=10, label='Tilt A (deg)')\n",
        "    plt.colorbar(scatter, ax=ax, label='Tilt Angle A (degrees)')\n",
        "\n",
        "    if simulate_bed:\n",
        "        unique_phis = np.unique(As)\n",
        "        if len(unique_phis) > 5:\n",
        "            unique_phis = np.linspace(np.min(As), np.max(As), 5)\n",
        "\n",
        "        x_grid, y_grid = np.meshgrid(np.linspace(0, bed_size_x, 20), np.linspace(0, bed_size_y, 20))\n",
        "        for phi_deg in unique_phis:\n",
        "            phi_rad = np.deg2rad(phi_deg)\n",
        "            z_bed = simulate_bed_surface(x_grid, y_grid, phi_rad, pivot_x, bed_offset)\n",
        "            ax.plot_surface(x_grid, y_grid, z_bed, color='green', alpha=0.3, label=f'Bed at {phi_deg:.1f}°')\n",
        "\n",
        "    ax.set_xlabel('X (mm)')\n",
        "    ax.set_ylabel('Y (mm)')\n",
        "    ax.set_zlabel('Z (mm)')\n",
        "    ax.set_title('G-code Toolpath Visualization with Tilt')\n",
        "    ax.legend()\n",
        "    ax.view_init(elev=30, azim=45)\n",
        "    plt.show()\n",
        "\n",
        "# Execute the visualization\n",
        "moves = parse_gcode(gcode_file)\n",
        "visualize_gcode(moves, bed_offset, pivot_x, bed_size_x, bed_size_y, simulate_bed)"
      ],
      "metadata": {
        "id": "t-pZqIHzheaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly  # Uncomment if issues\n"
      ],
      "metadata": {
        "id": "gXZy9kbS-hgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Plotly if needed (pre-installed in Colab, but just in case)\n",
        "\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# User-configurable variables (edit these as needed)\n",
        "gcode_file = 'output_gcode/pi 3mm.gcode'  # Upload your G-code to Colab and set the path (e.g., '/content/your_model.gcode')\n",
        "bed_offset = 41.5  # mm\n",
        "pivot_x = 0.0  # mm; updated to center at X=0\n",
        "bed_size_x = 200  # mm; from -100 to 100\n",
        "bed_size_y = 235  # mm; assuming Y unchanged, adjust if needed\n",
        "bed_min_x = -bed_size_x / 2  # -100\n",
        "bed_max_x = bed_size_x / 2   # 100\n",
        "simulate_bed = True  # Set to False to disable bed simulation\n",
        "\n",
        "# Function to parse G-code (unchanged)\n",
        "def parse_gcode(file_path):\n",
        "    moves = []\n",
        "    current_pos = {'X': 0, 'Y': 0, 'Z': 0, 'A': 0, 'E': 0}\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(';'):\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            command = parts[0]\n",
        "            if command not in ['G0', 'G1']:\n",
        "                continue\n",
        "            params = {}\n",
        "            for part in parts[1:]:\n",
        "                if part[0] in ['X', 'Y', 'Z', 'A', 'E', 'F']:\n",
        "                    params[part[0]] = float(part[1:])\n",
        "            for key in ['X', 'Y', 'Z', 'A', 'E']:\n",
        "                if key in params:\n",
        "                    current_pos[key] = params[key]\n",
        "            moves.append({\n",
        "                'command': command,\n",
        "                'X': current_pos['X'],\n",
        "                'Y': current_pos['Y'],\n",
        "                'Z': current_pos['Z'],\n",
        "                'A': current_pos['A'],\n",
        "                'E': current_pos.get('E', 0),\n",
        "            })\n",
        "    return moves\n",
        "\n",
        "# Function to simulate bed surface (updated for new X range)\n",
        "def simulate_bed_surface(x_grid, y_grid, phi_rad, pivot_x, bed_offset):\n",
        "    l_grid = x_grid - pivot_x\n",
        "    delta_z_bed = -np.sin(phi_rad) * l_grid + (np.cos(phi_rad) - 1) * bed_offset\n",
        "    return delta_z_bed\n",
        "\n",
        "# Function to visualize with Plotly (faster and interactive)\n",
        "def visualize_gcode(moves, bed_offset, pivot_x, bed_min_x, bed_max_x, bed_size_y, simulate_bed=True):\n",
        "    xs, ys, zs, As, commands, extrusions = [], [], [], [], [], []\n",
        "    for move in moves:\n",
        "        xs.append(move['X'])\n",
        "        ys.append(move['Y'])\n",
        "        zs.append(move['Z'])\n",
        "        As.append(move['A'])\n",
        "        commands.append(move['command'])\n",
        "        extrusions.append(move['E'])\n",
        "\n",
        "    xs = np.array(xs)\n",
        "    ys = np.array(ys)\n",
        "    zs = np.array(zs)\n",
        "    As = np.array(As)\n",
        "\n",
        "    # Create figure\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Plot path as lines, segmented by move type for performance\n",
        "    line_segments_print = {'x': [], 'y': [], 'z': []}\n",
        "    line_segments_travel = {'x': [], 'y': [], 'z': []}\n",
        "    prev_x, prev_y, prev_z = None, None, None\n",
        "    current_segment = None\n",
        "    for i in range(len(moves)):\n",
        "        if prev_x is not None:\n",
        "            if commands[i] == 'G1' and extrusions[i] > 0:\n",
        "                if current_segment != 'print':\n",
        "                    if line_segments_travel['x']:  # Add previous travel if any\n",
        "                        fig.add_trace(go.Scatter3d(x=line_segments_travel['x'], y=line_segments_travel['y'], z=line_segments_travel['z'],\n",
        "                                                   mode='lines', line=dict(color='blue', width=2), name='Travel', showlegend=False if current_segment else True))\n",
        "                    line_segments_travel = {'x': [], 'y': [], 'z': []}\n",
        "                    current_segment = 'print'\n",
        "                line_segments_print['x'].extend([prev_x, xs[i], None])  # None for break\n",
        "                line_segments_print['y'].extend([prev_y, ys[i], None])\n",
        "                line_segments_print['z'].extend([prev_z, zs[i], None])\n",
        "            else:\n",
        "                if current_segment != 'travel':\n",
        "                    if line_segments_print['x']:\n",
        "                        fig.add_trace(go.Scatter3d(x=line_segments_print['x'], y=line_segments_print['y'], z=line_segments_print['z'],\n",
        "                                                   mode='lines', line=dict(color='red', width=2), name='Print', showlegend=False if current_segment else True))\n",
        "                    line_segments_print = {'x': [], 'y': [], 'z': []}\n",
        "                    current_segment = 'travel'\n",
        "                line_segments_travel['x'].extend([prev_x, xs[i], None])\n",
        "                line_segments_travel['y'].extend([prev_y, ys[i], None])\n",
        "                line_segments_travel['z'].extend([prev_z, zs[i], None])\n",
        "        prev_x, prev_y, prev_z = xs[i], ys[i], zs[i]\n",
        "\n",
        "    # Add final segments\n",
        "    if line_segments_print['x']:\n",
        "        fig.add_trace(go.Scatter3d(x=line_segments_print['x'], y=line_segments_print['y'], z=line_segments_print['z'],\n",
        "                                   mode='lines', line=dict(color='red', width=2), name='Print'))\n",
        "    if line_segments_travel['x']:\n",
        "        fig.add_trace(go.Scatter3d(x=line_segments_travel['x'], y=line_segments_travel['y'], z=line_segments_travel['z'],\n",
        "                                   mode='lines', line=dict(color='blue', width=2), name='Travel'))\n",
        "\n",
        "    # Scatter points colored by tilt angle A\n",
        "    fig.add_trace(go.Scatter3d(x=xs, y=ys, z=zs, mode='markers',\n",
        "                               marker=dict(size=3, color=As, colorscale='Cividis', showscale=True,\n",
        "                                           colorbar=dict(title='Tilt A (deg)')),\n",
        "                               name='Points by Tilt'))\n",
        "\n",
        "    if simulate_bed:\n",
        "        unique_phis = np.unique(As)\n",
        "        if len(unique_phis) > 5:\n",
        "            unique_phis = np.linspace(np.min(As), np.max(As), 5)\n",
        "\n",
        "        x_grid, y_grid = np.meshgrid(np.linspace(bed_min_x, bed_max_x, 20), np.linspace(0, bed_size_y, 20))\n",
        "        for phi_deg in unique_phis:\n",
        "            phi_rad = np.deg2rad(phi_deg)\n",
        "            z_bed = simulate_bed_surface(x_grid, y_grid, phi_rad, pivot_x, bed_offset)\n",
        "            fig.add_trace(go.Surface(x=x_grid, y=y_grid, z=z_bed, opacity=0.3, colorscale='Greens',\n",
        "                                     showscale=False, name=f'Bed at {phi_deg:.1f}°'))\n",
        "\n",
        "    # Layout\n",
        "    fig.update_layout(title='G-code Toolpath Visualization with Tilt (Interactive)',\n",
        "                      scene=dict(xaxis_title='X (mm)', yaxis_title='Y (mm)', zaxis_title='Z (mm)',\n",
        "                                 aspectmode='manual', aspectratio=dict(x=1, y=1, z=0.5)),\n",
        "                      height=800, width=1000)\n",
        "    fig.show()\n",
        "\n",
        "# Execute the visualization\n",
        "moves = parse_gcode(gcode_file)\n",
        "visualize_gcode(moves, bed_offset, pivot_x, bed_min_x, bed_max_x, bed_size_y, simulate_bed)"
      ],
      "metadata": {
        "id": "ks2qH2xehhHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}